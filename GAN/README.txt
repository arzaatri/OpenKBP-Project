Using the GAN

Functions are provided to automate dataloading for, as well as construction and training of, the GAN network.

PREPROCESSING
dataprep.py automates all preprocessing of data. Data should be in the following director: ../open-kbp-master/provided-data, and it will be saved in the director: /Data

DATALOADING
dataloaders.py provides the function get_dataloaders, which returns dataloaders for the train, val, and test sets. The parameters and respectively the train, validation, and test batch sizes. This module makes use of augmentation.py for data augmentation helper functions.

GAN CONSTRUCTION
The module pix2pix.py contains the get_models function, which returns the discriminator and the generator. The arguments are respectively: number of output filters for the first discriminator convolution; depth of the discriminator (i.e. number of convolutions); number of output filters for the first generator convolution; depth of the generator (i.e. number of downsamplings and upsamplings). model_parts.py contains class definitions used to simplify GAN construction in pix2pix.py.

TRAINING
train.py contains train_GAN, used to train the network and print per-epoch information. Its required arguments are as follows:

-A dict containing keys 'train' and 'val,' whose corresponding values are  the train and validation set dataloaders
-The discriminator
-The generator
-The loss function for the discriminator
-Discriminator's optimizer
-Generator's optimizer
-Discriminator's scheduler
-Generator's scheduler

And its arguments with defualt values are:

-Number of patches in one dimension generated by PatchGAN (default = 35)
-Whether to use pixelwise loss (defult = True. Unecessary; just use lambda_pixelwise=0.0)
-lambda_pixelwise (default = 1.0)
-n_epochs (default = 50)
-verbose (defualt = True; whether to print every epoch)
-print_each(default = 1; print each k epochs)

It returns the discriminator and generator with the best state_dicts loaded; the the accuracy dict for the discriminator (true labels), as well as one for false labels; the loss dict for the discriminator, as well as one for the generator; a dict of dose scores; and the best epoch index. All dicts contain train and val information.

If chnaging the discriminator architecture, one can skip the computation of the number of patches by running the code and reading the error message that pops up

NOTEBOOKS
GAN.ipynb can be used for training a GAN and saving the output. Plotting_and_testing.ipynb can be used for plotting training curves and compute tests dose scores.